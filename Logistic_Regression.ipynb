{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCXT341mzyQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52f643e-7865-4c6c-afcf-42a4131b0c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('ml-diabetes').getOrCreate"
      ],
      "metadata": {
        "id": "XU6hFAglAzQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv('/content/diabetes (1).csv',header=True,inferSchema=True)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "2FLlsmQoAzTW",
        "outputId": "94e617a9-1136-4e78-f270-d27284ecd10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'read'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-94f0be457da1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/diabetes (1).csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'read'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(df.take(5),columns=df.columns).transpose"
      ],
      "metadata": {
        "id": "xwkuVHYWAzZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "7Z6NXL1AAzeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.toPandas()"
      ],
      "metadata": {
        "id": "Pe5uFY2tAzlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Outcome').count().toPandas()"
      ],
      "metadata": {
        "id": "xvs-CBkBAzou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making numerical features\n",
        "numeric_features=[t[0] for t in df.types if t[1]=='int']"
      ],
      "metadata": {
        "id": "BzPdWBfLAzru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features"
      ],
      "metadata": {
        "id": "bvcoD5iXAzuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9ZaKmInCeGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(numeric_features).describe().toPandas().transpose()"
      ],
      "metadata": {
        "id": "zKmbLRqIAzw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "numeric_data=df.select(numeric_features).toPandas()\n",
        "\n",
        "axs=scatter_matrix(numeric_data,figsize=(8,8));\n",
        "\n",
        "# Rotate axis labels and remove axis ticks\n",
        "n=len(numeric_data.columns)\n",
        "for i in range(n):\n",
        "  v=axis[i,0]\n",
        "  v.yaxis.label.set_rotation(0)\n",
        "  v.yaxis.label.set_ha('right')\n",
        "  v.set_yticks(())\n",
        "  h=axs[n-1,i]\n",
        "  h.xaxis.label.set_rotation(90)\n",
        "  h.set_xticks(())"
      ],
      "metadata": {
        "id": "1LKzJE0gAzzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import isnull,when,count,col"
      ],
      "metadata": {
        "id": "7qDMVtYTAz2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c),c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "id": "yyt6LWXyAz42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=df.drop('SkinThickness')\n",
        "dataset=dataset.drop('Insulin')\n",
        "dataset_new=dataset.drop('DiabetesPedigreeFunction')\n",
        "dataset_final=dataset_new.drop('Pregnancies')\n",
        "\n",
        "dataset_final.show()"
      ],
      "metadata": {
        "id": "J2mOa9vyAz7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required_features=['Glucose','BloodPressure','BMI','Age']\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler=VectorAssembler(inputCols=required_features,outputCol='features')\n",
        "\n",
        "treansformed_data=assembler.transform(dataset_final)\n",
        "transformed_data.show()"
      ],
      "metadata": {
        "id": "tUp1AR6HAz-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "(training_data,test_data)=transformed_data.randomSplit([0.8,0.2],seed=10)\n",
        "\n",
        "print('Training Dataset Count:'+str(training_data.count()))\n",
        "print('Test Dataset Count:'+ str(test_data.count()))"
      ],
      "metadata": {
        "id": "SuELNwPUA0Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr=LogisticRegression(featuresCol='features',labelCol='Outcome',maxIter=50)\n",
        "lrModel=lr.fit(training_data)\n",
        "lr_predictions=lrModel.transform(test_data)"
      ],
      "metadata": {
        "id": "5fPbOkVMA0G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol = 'Outcome', metricName = 'accuracy')\n",
        "print('Logistic Regression Accuracy:', multi_evaluator.evaluate(lr_predictions))"
      ],
      "metadata": {
        "id": "j6JeCQIEA0KP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}